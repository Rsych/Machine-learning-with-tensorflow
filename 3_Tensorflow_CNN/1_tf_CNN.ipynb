{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Rsych/Machine-learning-with-tensorflow/blob/main/3_Tensorflow_CNN/1_tf_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning with Tensorflow - Fundamentals Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution neural network (CNN) is very suitable for image classification due to its use of spatial information. This neural network was driven from receptive fields in in the visual cortex.\n",
    "![cnn](img/cnn.png)\n",
    "There are 3 main factors in CNN. \n",
    "\n",
    "* Local receptive field\n",
    "* Shared weights and biases\n",
    "* Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local receptive field\n",
    "\n",
    "If you want to save spatial information from images or other shaped data, it's easier to save them as matrix. To encode local structure into matrix is to connect its nearest input neurons' submatrices to a hidden neuron in next layer. This hidden neuron shows a local receptive field and this action is called \"Convolution\" and with neural network consists of this job is called convolution neural network. In addition, submatrices can be overlapped to encode more information in it. How it operates we'll see later with matrix sliding window function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared weights and biases\n",
    "By sharing weights and biases, each layers learn the weights to detect feature at different parts of the image. This means that all the neurons in the layer detect exactly the same feature, just at different locations in the input. These weights that define the feature map are also called kernels or filters. One or more functional maps are required to perform image recognition. So a convolutional layer consists of several different feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical explanation\n",
    "\n",
    "The best way to understand what convolution is, to see how sliding window function applied to matrix works. From next image, given input matrix I and K we get convoluted output. 3x3 kernel K (aka filter or feature detector) is multiplied to each element of input matrix and calculated a cell.\n",
    "\n",
    "![sliding](img/slidingMatrix.png)\n",
    "\n",
    "Here we decided to stop sliding window when it hits edge of I. Therefore output is 3x3. We can fill input with zeros (output is 5x5). This is decided depending on padding. Kernel depth is same as input depth (channel). \n",
    "\n",
    "Also, there's feature called \"stride\", it is about how far sliding window is sliding. Bigger stride, output size is smaller, smaller stride, more output is made and contains more information. \n",
    "\n",
    "Filter size, stride, and padding is used to optimize hyper-parameter for  neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to start with CNN\n",
    "\n",
    "To write 32 parallel features and 3x3 filter size convolution layer in Tensorflow 2 we start from this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single input filter 28x28 image applied 3x3 convolution, outputs 32 channel. This can be seen in Fig. 1 convolutions layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "Pooling layer is used to reduce dimensions of the feature maps to reduce the amount of parameters and computation performed in the network. Pooling layer operates on each feature map independently. There are two types of pooling used: \n",
    "\n",
    "* Max pooling\n",
    "* Average pooling\n",
    "\n",
    "Max pooling is the most general selection, it simply outputs maximum activation. In keras to perform 2x2 size max pooling layer is\n",
    "![maxpooling](img/maxpooling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "model.add(MaxPooling2D((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average pooling outputs average activation in given area. Keras has many different level of poolings. You can check it on [Keras official page](https://keras.io/api/layers/pooling_layers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "\n",
    "We've looked into basic concept of CNN. CNN operates convolution and pooling differently depending on dimension of information of input. \n",
    "* Audio and text data(`time`) - 1st dimension\n",
    "* Image(`height*width`).- 2nd dimension \n",
    "* Video(`height*width*time`) - 3rd dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNxUkQ1KHRq7ROtTQI+Yr/m",
   "include_colab_link": true,
   "name": "1_tf_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
